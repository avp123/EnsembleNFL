{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avp123/EnsembleNFL/blob/main/Pre_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNE7n9L9EJZq",
        "outputId": "d5f08d60-8b88-4a48-88be-3b5ab91f43c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnhTAAbEEhB2",
        "outputId": "c36324d4-4ef9-4a22-8e76-8f3f9e98dd53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "catboost_info\t\t       master-boxscore-tracker.xlsx\n",
            "compiled-boxscores.xlsx        removed-na-rows-master-boxscore-tracker1.xlsx\n",
            "master-boxscore-tracker1.xlsx  streamlitDataNFLModel.xlsx\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Ashray Pamula/data\")\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "POwUa6vOFFd1",
        "outputId": "8d610592-9dca-40ac-f863-fa9bb7de024f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Line  Home Favored    Home QBR    Away QBR  Home PPG  Away PPG  \\\n",
              "0      2.0             1    0.000000    0.000000    0.0000    0.0000   \n",
              "1      2.0             0    0.000000    0.000000    0.0000    0.0000   \n",
              "2      3.0             0    0.000000    0.000000    0.0000    0.0000   \n",
              "3      4.5             1    0.000000    0.000000    0.0000    0.0000   \n",
              "4      2.5             1    0.000000    0.000000    0.0000    0.0000   \n",
              "...    ...           ...         ...         ...       ...       ...   \n",
              "4480   0.0             0  107.262404  107.567617   25.6000   30.2000   \n",
              "4481   2.5             1  100.544632   88.934373   23.6250   19.6250   \n",
              "4482   4.0             1   95.188172  113.854167   26.2500   25.1250   \n",
              "4483   8.0             1  107.703672  110.159156   28.6250   25.4375   \n",
              "4484   1.5             0   97.366775  106.547389   24.0625   25.3125   \n",
              "\n",
              "      Home PTS Allowed  Away PTS Allowed   Home TO   Away TO  ...  \\\n",
              "0               0.0000          0.000000  0.000000  0.000000  ...   \n",
              "1               0.0000          0.000000  0.000000  0.000000  ...   \n",
              "2               0.0000          0.000000  0.000000  0.000000  ...   \n",
              "3               0.0000          0.000000  0.000000  0.000000  ...   \n",
              "4               0.0000          0.000000  0.000000  0.000000  ...   \n",
              "...                ...               ...       ...       ...  ...   \n",
              "4480           24.8000         19.266667  1.333333  1.533333  ...   \n",
              "4481           24.0625         16.187500  1.375000  1.187500  ...   \n",
              "4482           14.0625         20.687500  0.937500  1.062500  ...   \n",
              "4483           21.3125         18.937500  0.500000  1.250000  ...   \n",
              "4484           22.1250         24.875000  1.437500  1.250000  ...   \n",
              "\n",
              "      Away Road Win PCT  Home Win Streak  Away Win Streak  Home QBR Advantage  \\\n",
              "0              0.000000                0                0                   1   \n",
              "1              0.000000                0                0                   1   \n",
              "2              0.000000                0                0                   1   \n",
              "3              0.000000                0                0                   1   \n",
              "4              0.000000                0                0                   1   \n",
              "...                 ...              ...              ...                 ...   \n",
              "4480           0.857143                0                1                   0   \n",
              "4481           0.750000                0                0                   1   \n",
              "4482           0.625000                0                1                   0   \n",
              "4483           0.500000                3                0                   0   \n",
              "4484           0.875000                4                0                   0   \n",
              "\n",
              "      Home PPG Advantage  Home PTS Allowed Advantage  Home TO Advantage  \\\n",
              "0                      1                           1                  0   \n",
              "1                      1                           1                  0   \n",
              "2                      1                           1                  0   \n",
              "3                      1                           1                  0   \n",
              "4                      1                           1                  0   \n",
              "...                  ...                         ...                ...   \n",
              "4480                   0                           1                  1   \n",
              "4481                   1                           1                  0   \n",
              "4482                   1                           0                  1   \n",
              "4483                   1                           1                  1   \n",
              "4484                   0                           0                  0   \n",
              "\n",
              "      Home Win PCT Advantage  Dif PPG  Dif PTS Allowed  \n",
              "0                          1   0.0000         0.000000  \n",
              "1                          1   0.0000         0.000000  \n",
              "2                          1   0.0000         0.000000  \n",
              "3                          1   0.0000         0.000000  \n",
              "4                          1   0.0000         0.000000  \n",
              "...                      ...      ...              ...  \n",
              "4480                       0  -4.6000        -5.533333  \n",
              "4481                       1   4.0000        -7.875000  \n",
              "4482                       1   1.1250         6.625000  \n",
              "4483                       1   3.1875        -2.375000  \n",
              "4484                       0  -1.2500         2.750000  \n",
              "\n",
              "[4485 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73e281da-667d-4e33-8eb7-0cd7ccbd415f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Line</th>\n",
              "      <th>Home Favored</th>\n",
              "      <th>Home QBR</th>\n",
              "      <th>Away QBR</th>\n",
              "      <th>Home PPG</th>\n",
              "      <th>Away PPG</th>\n",
              "      <th>Home PTS Allowed</th>\n",
              "      <th>Away PTS Allowed</th>\n",
              "      <th>Home TO</th>\n",
              "      <th>Away TO</th>\n",
              "      <th>...</th>\n",
              "      <th>Away Road Win PCT</th>\n",
              "      <th>Home Win Streak</th>\n",
              "      <th>Away Win Streak</th>\n",
              "      <th>Home QBR Advantage</th>\n",
              "      <th>Home PPG Advantage</th>\n",
              "      <th>Home PTS Allowed Advantage</th>\n",
              "      <th>Home TO Advantage</th>\n",
              "      <th>Home Win PCT Advantage</th>\n",
              "      <th>Dif PPG</th>\n",
              "      <th>Dif PTS Allowed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4480</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>107.262404</td>\n",
              "      <td>107.567617</td>\n",
              "      <td>25.6000</td>\n",
              "      <td>30.2000</td>\n",
              "      <td>24.8000</td>\n",
              "      <td>19.266667</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.533333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-4.6000</td>\n",
              "      <td>-5.533333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4481</th>\n",
              "      <td>2.5</td>\n",
              "      <td>1</td>\n",
              "      <td>100.544632</td>\n",
              "      <td>88.934373</td>\n",
              "      <td>23.6250</td>\n",
              "      <td>19.6250</td>\n",
              "      <td>24.0625</td>\n",
              "      <td>16.187500</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>1.187500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0000</td>\n",
              "      <td>-7.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4482</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>95.188172</td>\n",
              "      <td>113.854167</td>\n",
              "      <td>26.2500</td>\n",
              "      <td>25.1250</td>\n",
              "      <td>14.0625</td>\n",
              "      <td>20.687500</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>1.062500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.1250</td>\n",
              "      <td>6.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4483</th>\n",
              "      <td>8.0</td>\n",
              "      <td>1</td>\n",
              "      <td>107.703672</td>\n",
              "      <td>110.159156</td>\n",
              "      <td>28.6250</td>\n",
              "      <td>25.4375</td>\n",
              "      <td>21.3125</td>\n",
              "      <td>18.937500</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.1875</td>\n",
              "      <td>-2.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4484</th>\n",
              "      <td>1.5</td>\n",
              "      <td>0</td>\n",
              "      <td>97.366775</td>\n",
              "      <td>106.547389</td>\n",
              "      <td>24.0625</td>\n",
              "      <td>25.3125</td>\n",
              "      <td>22.1250</td>\n",
              "      <td>24.875000</td>\n",
              "      <td>1.437500</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.2500</td>\n",
              "      <td>2.750000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4485 rows × 34 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73e281da-667d-4e33-8eb7-0cd7ccbd415f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73e281da-667d-4e33-8eb7-0cd7ccbd415f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73e281da-667d-4e33-8eb7-0cd7ccbd415f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "path = \"/content/drive/MyDrive/Ashray Pamula/data/master-boxscore-tracker.xlsx\"\n",
        "#path = \"/content/drive/MyDrive/Ashray Pamula/data/master-boxscore-tracker1.xlsx\"\n",
        "#path = \"/content/drive/MyDrive/Ashray Pamula/data/removed-na-rows-master-boxscore-tracker1.xlsx\"\n",
        "df = pd.read_excel(path)\n",
        "df.head()\n",
        "df.shape\n",
        "df.isna().sum()\n",
        "\n",
        "df2 = df.loc[:, \"Line\":]\n",
        "#df2 = df.loc[:, \"Home QBR\":]\n",
        "#df2 = df2.drop([\"Home Home Win Streak\", \"Home Home Win PCT\", \"Away Road Win PCT\"], axis = 1)\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdKbuOCwICXw",
        "outputId": "3813649e-b333-4d1f-b5d2-e0c56445aaaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8.08689034e-01 7.14846641e-02 5.47244011e-02 5.43393240e-02\n",
            " 3.77304312e-03 3.52747890e-03 9.10355611e-04 8.45383112e-04\n",
            " 4.28677509e-04 3.34769326e-04 2.67836292e-04 2.45359464e-04\n",
            " 1.15528619e-04 7.09919904e-05 5.89236377e-05 5.28308495e-05\n",
            " 4.88419951e-05 3.22690191e-05 9.80748944e-06 8.64908056e-06\n",
            " 6.10883552e-06 5.15523006e-06 4.82910629e-06 2.98771860e-06\n",
            " 2.86423636e-06 2.51507886e-06 1.91892575e-06 1.83891403e-06\n",
            " 1.68033613e-06 1.22101856e-06 4.12464104e-07 2.98532468e-07]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = \"mle\")\n",
        "principal_components = pca.fit_transform(df2)\n",
        "print(pca.explained_variance_ratio_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TGmI2DTWbr0",
        "outputId": "79acf92f-0292-4e20-e982-54145d9b94a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4485, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "principal_df = pd.DataFrame(data = principal_components)\n",
        "principal_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WN3f8RejGe1_"
      },
      "outputs": [],
      "source": [
        "df[\"Home Win\"] = df[\"Home Win\"].astype(int)\n",
        "y = np.array(df[\"Home Win\"])\n",
        "X = np.array(df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKbW5M6MM7lk"
      },
      "outputs": [],
      "source": [
        "#Feature Selection\n",
        "\n",
        "#Removing Features with low variance\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
        "X = sel.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1O6pVxKFfH8w"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=10) # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRRjavJcvmZT"
      },
      "outputs": [],
      "source": [
        "X_train = X[df[\"Season\"] != 2019]\n",
        "X_test = X[df[\"Season\"] == 2019]\n",
        "y_train = y[df[\"Season\"] != 2019]\n",
        "y_test = y[df[\"Season\"] == 2019]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87Oa90uTfM_z",
        "outputId": "44cb6e52-1150-4f8e-c32f-4b0579736c74"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.6067415730337079"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# STEP 1: Initialization\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_model = LogisticRegression(C = 41, random_state = 0)\n",
        "\n",
        "# STEP 2: Training\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "# STEP 3: Prediction\n",
        "#predictions = logistic_model.predict_proba(X_test)\n",
        "predictions = logistic_model.predict(X_test)\n",
        "# STEP 4: Evaluation\n",
        "from sklearn.metrics import accuracy_score\n",
        "#print(predictions)\n",
        "accuracy_score(y_test, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "67ucLfjPkfuk",
        "outputId": "3f4e3f33-9688-476f-bb11-c4859efc288b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1f44e454ebd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# STEP 1: Initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mnfl_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CatBoostClassifier' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier #n_estimators = 80\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier #66.55%: n_estimators = 12, learning_rate = 0.05, max_depth = 1, random_state = 0\n",
        "from sklearn.ensemble import AdaBoostClassifier #66.55%: n_estimators = 3\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#pca = PCA(n_components = 31)\n",
        "#X_train = pca.fit(X_train)\n",
        "#X_test = pca.fit_transform(X_test)\n",
        "#print(pd.DataFrame(X_train).head())\n",
        "\n",
        "# STEP 1: Initialization\n",
        "nfl_model = CatBoostClassifier(learning_rate = 0.03, iterations = 500, depth = 2)\n",
        "\n",
        "\n",
        "# STEP 2: Training\n",
        "nfl_model.fit(X_train, y_train)\n",
        "\n",
        "# STEP 3: Prediction\n",
        "predictions = nfl_model.predict(X_test)\n",
        "#predictions = nfl_model.predict_proba(X_test)\n",
        "\n",
        "# STEP 4: Evaluation\n",
        "accuracy_score(y_test, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eFcXG18_3Yd"
      },
      "outputs": [],
      "source": [
        "!pip install optuna\n",
        "import optuna\n",
        "from optuna.integration import CatBoostPruningCallback\n",
        "\n",
        "def objective(trial: optuna.Trial) -> float:\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    param = {\n",
        "        \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n",
        "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1, log=True),\n",
        "        \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
        "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
        "        \"bootstrap_type\": trial.suggest_categorical(\n",
        "            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
        "        ),\n",
        "        \"used_ram_limit\": \"3gb\",\n",
        "        \"eval_metric\": \"Accuracy\",\n",
        "    }\n",
        "\n",
        "    if param[\"bootstrap_type\"] == \"Bayesian\":\n",
        "        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
        "    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n",
        "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1, log=True)\n",
        "\n",
        "    gbm = cb.CatBoostClassifier(**param)\n",
        "\n",
        "    pruning_callback = CatBoostPruningCallback(trial, \"Accuracy\")\n",
        "    gbm.fit(\n",
        "        train_x,\n",
        "        train_y,\n",
        "        eval_set=[(valid_x, valid_y)],\n",
        "        verbose=0,\n",
        "        early_stopping_rounds=100,\n",
        "        callbacks=[pruning_callback],\n",
        "    )\n",
        "\n",
        "    # evoke pruning manually.\n",
        "    pruning_callback.check_pruned()\n",
        "\n",
        "    preds = gbm.predict(valid_x)\n",
        "    pred_labels = np.rint(preds)\n",
        "    accuracy = accuracy_score(valid_y, pred_labels)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=5), direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100, timeout=600)\n",
        "\n",
        "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: {}\".format(trial.value))\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWw0Oecefiqv"
      },
      "outputs": [],
      "source": [
        "best_accuracy = 0\n",
        "best_param = 0\n",
        "new_acc = 0\n",
        "\n",
        "mae_values = []\n",
        "\n",
        "for k in float_for_loop(90, 300, 1):\n",
        "  random_forest_model = LGBMClassifier(max_depth = 1, learning_rate = .166, n_estimators = 90)\n",
        "  random_forest_model.fit(X_train, y_train)\n",
        "  predictions = random_forest_model.predict(X_test)\n",
        "  mae_values.append(accuracy_score(y_test, predictions))\n",
        "  new_acc = accuracy_score(y_test, predictions)\n",
        "  if(new_acc > best_accuracy):\n",
        "    best_accuracy = new_acc\n",
        "    best_param = k\n",
        "\n",
        "#67.7362 at 90\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(90, 300), mae_values)\n",
        "\n",
        "print(\"Accuracy:\", best_accuracy)\n",
        "print(\"Best k-value:\", best_param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hReXsbM5T65S"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(mae_values)\n",
        "\n",
        "print(\"Accuracy:\", best_accuracy)\n",
        "print(\"Best k-value:\", best_param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqdoBQQ_9nch",
        "outputId": "16bf57ab-ff2e-40d0-b1e7-8476b4c3fd39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2-cp310-cp310-manylinux2014_x86_64.whl (98.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (3.3.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm) (0.40.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (1.7.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.10.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install catboost\n",
        "%pip install lightgbm\n",
        "%pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n2AntzP92to"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2MXBfEXyQfK"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier #n_estimators = 80\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier #66.55%: n_estimators = 12, learning_rate = 0.05, max_depth = 1, random_state = 0\n",
        "from sklearn.ensemble import AdaBoostClassifier #66.55%: n_estimators = 3\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from itertools import product\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model_accuracy = []"
      ],
      "metadata": {
        "id": "hmgbLBXfjzZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGLlEP38qdcj"
      },
      "outputs": [],
      "source": [
        "year = 2019\n",
        "\n",
        "#X_train = X[df[\"Season\"] != year]\n",
        "X_test = X[df[\"Season\"] == year]\n",
        "#y_train = y[df[\"Season\"] != year]\n",
        "y_test = y[df[\"Season\"] == year]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fB6v__XF0Uo",
        "outputId": "c7be9e31-ff71-4ae3-853c-781e23c4ddd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 0.6292134831460674 (+/- 0.01) [Decision Tree]\n",
            "Accuracy Score: 0.6329588014981273 (+/- 0.01) [Ada Boost]\n",
            "Accuracy Score: 0.6816479400749064 (+/- 0.01) [Gradient Boosting]\n",
            "Accuracy Score: 0.5917602996254682 (+/- 0.01) [Logistic Regression]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 0.6292134831460674 (+/- 0.01) [Random Forest]\n",
            "Accuracy Score: 0.602996254681648 (+/- 0.01) [SVC]\n",
            "Accuracy Score: 0.6254681647940075 (+/- 0.01) [KNN]\n",
            "Accuracy Score: 0.6479400749063671 (+/- 0.01) [GaussianNB]\n",
            "Accuracy Score: 0.6367041198501873 (+/- 0.01) [BernoulliNB]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 0.5730337078651685 (+/- 0.01) [MLP]\n",
            "Accuracy Score: 0.6292134831460674 (+/- 0.01) [CatBoost]\n",
            "Accuracy Score: 0.6292134831460674 (+/- 0.01) [XGBoost]\n",
            "Accuracy Score: 0.6329588014981273 (+/- 0.01) [LightGBM]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 0.6367041198501873 (+/- 0.01) [Ensemble]\n"
          ]
        }
      ],
      "source": [
        "# Voting Classifier\n",
        "\n",
        "# Training classifiers\n",
        "clf1 = DecisionTreeClassifier(max_depth = 1, min_samples_split = 12, random_state = 0)\n",
        "# = 2019\n",
        "#clf1 = DecisionTreeClassifier(max_depth = 5, min_samples_split = 12, random_state = 0)\n",
        "\n",
        "clf2 = AdaBoostClassifier(n_estimators = 8, learning_rate = .26, random_state = 0)\n",
        "#clf2 = AdaBoostClassifier(n_estimators = 9, learning_rate = .30, random_state = 0)\n",
        "\n",
        "clf3 = GradientBoostingClassifier(n_estimators = 46, learning_rate = .03, max_depth = 5, min_samples_split = 34, random_state = 0)\n",
        "#clf3 = GradientBoostingClassifier(n_estimators = 33, learning_rate = .04, max_depth = 10, min_samples_split = 14, random_state = 0)\n",
        "\n",
        "clf4 = LogisticRegression(C = .14, random_state = 0)\n",
        "#clf4 = LogisticRegression(C = 41, random_state = 0)\n",
        "\n",
        "clf5 = RandomForestClassifier(n_estimators = 417, max_depth = 3, min_samples_split = 2, random_state=0)\n",
        "#clf5 = RandomForestClassifier(n_estimators = 127, max_depth = 17, random_state=0, min_samples_split = 2)\n",
        "\n",
        "clf6 = SVC(C = 173, kernel = \"poly\", degree = 2, probability = True, random_state = 0)\n",
        "#clf6 = SVC(C = 18, kernel = \"poly\", degree = 1, probability = True, random_state = 0)\n",
        "\n",
        "clf7 = KNeighborsClassifier(n_neighbors = 58)\n",
        "#clf7 = KNeighborsClassifier(n_neighbors = 32)\n",
        "\n",
        "clf8 = GaussianNB()\n",
        "#clf8 = GaussianNB()\n",
        "\n",
        "clf9 = BernoulliNB(alpha = 194, fit_prior = False)\n",
        "#clf9 = BernoulliNB(alpha = 20, fit_prior = False)\n",
        "\n",
        "clf10 = MLPClassifier(alpha = 60, max_iter = 48, random_state = 0)\n",
        "#clf10 = MLPClassifier(alpha = 37, max_iter = 30, random_state = 0)\n",
        "\n",
        "clf11 = CatBoostClassifier(learning_rate = .04, iterations = 1000, depth = 1, silent = True)\n",
        "\n",
        "clf12 = XGBClassifier(max_depth = 1, learning_rate = .081, n_estimators = 100, silent = None)\n",
        "\n",
        "clf13 = LGBMClassifier(max_depth = 1, learning_rate = .166, n_estimators = 90)\n",
        "\n",
        "#try including these as well XGBoost, LightGBM, CatBoost\n",
        "\n",
        "\n",
        "eclf = VotingClassifier(estimators=[('dt', clf1), ('ab', clf2), ('gb', clf3), ('lr', clf4), ('rf', clf5), ('svc', clf6), ('knn', clf7), ('gnb', clf8), ('bnb', clf9), ('MLP', clf10), ('cbc', clf11), ('xgb', clf12), ('lgbm', clf13)], voting='hard')\n",
        "\n",
        "#params = {'svc__C': [.1, 1, 10, 100], 'svc__kernel': ['linear', 'rbf'], 'rf__n_estimators': [20, 40, 60, 80, 100, 120, 140, 160, 180, 200], 'knn__n_neighbors': [1, 5, 10, 20, 30, 40, 50], 'dt__max_depth': [1, 5, 10, 20, 30, 40,  50], 'dt__min_samples_split': [1, 5, 10, 20, 30, 40, 50], 'ab__n_estimators': [1, 5, 10, 20, 30, 40, 50], 'ab__learning_rate': [0.01, .1, .2, .4, .6, .8, 1], 'gb__n_estimators':[1, 5, 10, 20, 30, 40, 50], 'gb__learning_rate': [0.01, .1, .2, .4, .6, .8, 1], 'gb__max_depth': [1, 5, 10, 20, 30, 40,  50], 'gb__min_samples_split': [1, 5, 10, 20, 30, 40, 50]}\n",
        "\n",
        "#grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)\n",
        "#gridsearch = grid.fit(X_train, y_train)\n",
        "\n",
        "#print(gridsearch.best_params_)\n",
        "#grid_predictions = gridsearch.predict(X_test)\n",
        "\n",
        "\n",
        "#print(accuracy_score(y_test, grid_predictions))\n",
        "\n",
        "for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6, clf7, clf8, clf9, clf10, clf11, clf12, clf13, eclf], ['Decision Tree', 'Ada Boost', 'Gradient Boosting', 'Logistic Regression', 'Random Forest', 'SVC', 'KNN', 'GaussianNB', 'BernoulliNB', 'MLP', 'CatBoost', 'XGBoost', 'LightGBM', 'Ensemble']):\n",
        "  clf.fit(X_train, y_train)\n",
        "  predictions = clf.predict(X_test)\n",
        "  print(\"Accuracy Score:\", accuracy_score(y_test, predictions), \"(+/- 0.01) [\" + label + \"]\")\n",
        "\n",
        "  if(clf == eclf):\n",
        "    new_model_accuracy.append(accuracy_score(y_test, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3wq9yCWk50w",
        "outputId": "50907bc3-7ae4-4b80-fe0f-3538a8d2bde1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6532258064516129,\n",
              " 0.6820083682008368,\n",
              " 0.6497890295358649,\n",
              " 0.731404958677686,\n",
              " 0.5827067669172933,\n",
              " 0.7008196721311475,\n",
              " 0.65,\n",
              " 0.7017543859649122,\n",
              " 0.676923076923077,\n",
              " 0.6666666666666666,\n",
              " 0.6389891696750902,\n",
              " 0.714828897338403,\n",
              " 0.6854460093896714,\n",
              " 0.6517412935323383,\n",
              " 0.6796875,\n",
              " 0.6816479400749064,\n",
              " 0.6479400749063671,\n",
              " 0.6367041198501873]"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vT-D2Rdu7O2r"
      },
      "outputs": [],
      "source": [
        "vegas_accuracy = [63.037, 64.727, 69.582, 60.3, 66.142, 68.352, 68.914, 65.918, 66.292, 64.607, 70.709, 67.228, 62.687, 64.684, 69.63, 65.45, 64.23]\n",
        "model_accuracy = [64.51612903225806, 67.78242677824268, 64.13502109704642, 72.72727272727273, 57.5187969924812, 68.85245901639344, 65.38461538461539, 69.73684210526315, 66.15384615384615, 66.66666666666666, 62.45487364620939, 70.72243346007605, 67.6056338028169, 64.17910447761194, 66.796875, 67.79026217228464, 64.04494382022472, 63.29588014981273]\n",
        "#per week accuracy\n",
        "model_week_accuracy = [0.6563876651982379, 0.6523297491039427, 0.6410256410256411, 0.6352941176470588, 0.6827309236947792, 0.6411290322580645, 0.6816326530612244, 0.7, 0.6416666666666667, 0.5863453815261044, 0.7433962264150943, 0.7052238805970149, 0.6702898550724637, 0.7035714285714286, 0.6851851851851852, 0.6398305084745762, 0.6884615384615385]\n",
        "#new accuracy using train/test split from per week accuracy model\n",
        "new_model_accuracy = [0.6532258064516129, 0.6820083682008368, 0.6497890295358649, 0.731404958677686, 0.5827067669172933, 0.7008196721311475, 0.65, 0.7017543859649122, 0.676923076923077, 0.6666666666666666, 0.6389891696750902, 0.714828897338403, 0.6854460093896714, 0.6517412935323383, 0.6796875, 0.6816479400749064, 0.6479400749063671, 0.6367041198501873]\n",
        "\n",
        "x_axis = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
        "x2_axis = [2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
        "\n",
        "vegas_total_accuracy = 66.227\n",
        "total_accuracy = 67.291\n",
        "\n",
        "#new_model_total_accuracy = 66.85\n",
        "#model_week_acc = 66.79\n",
        "\n",
        "f, ax = plt.subplots(figsize=(20,8))\n",
        "\n",
        "ax.plot(x_axis, vegas_accuracy, color = 'c', label = \"Vegas Accuracy (Average: \" + str(vegas_total_accuracy) + \"%)\", alpha = .8, marker = 'o', mfc = 'black', mew = 0)\n",
        "ax.plot(x2_axis, model_accuracy, color = 'orange', label = \"Custom Model Accuracy (Average: \" + str(total_accuracy) + \"%)\", alpha = 1, marker = 'o', mfc = 'black', mew = 0)\n",
        "ax.legend(loc = 'best', )\n",
        "\n",
        "plt.xticks(ticks=[2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021])\n",
        "plt.yticks(ticks=[56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74])\n",
        "\n",
        "#plt.axhline(vegas_total_accuracy, alpha = 0.5, color = 'c', label = 'Vegas')\n",
        "#plt.axhline(total_accuracy, alpha = 0.5, color = 'orange', label = \"Homemade\")\n",
        "\n",
        "plt.ylabel(\"Prediction Accuracy (%)\")\n",
        "plt.xlabel(\"NFL Season\")\n",
        "plt.title(\"Comparing NFL Game Prediction Accuracy of Vegas Oddsmakers and Homemade Model\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2n7AKZzzbzRD"
      },
      "outputs": [],
      "source": [
        "# Gridsearch\n",
        "\n",
        "def float_for_loop(start, stop, increment):\n",
        "    while start < stop:\n",
        "        yield start\n",
        "        start += increment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN3Z15Dh8Rlw"
      },
      "outputs": [],
      "source": [
        "max_accuracy = 0\n",
        "for n_estimators in range(1, 100):\n",
        "  for learning_rate in float_for_loop(0.01, 1, 0.01):\n",
        "    for max_depth in range(1,20):\n",
        "      clf3 = GradientBoostingClassifier(n_estimators = n_estimators, learning_rate = learning_rate, max_depth = max_depth, random_state = 0)\n",
        "      clf3.fit(X_train, y_train)\n",
        "      predictions = clf3.predict(X_test)\n",
        "      new_accuracy = accuracy_score(y_test, predictions)\n",
        "      if (new_accuracy > max_accuracy):\n",
        "        max_accuracy = new_accuracy\n",
        "        best_n_estimators = n_estimators\n",
        "        best_learning_rate = learning_rate\n",
        "        best_max_depth = max_depth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP_fDWBd75kt"
      },
      "outputs": [],
      "source": [
        "grid.cv_results_\n",
        "grid.best_estimator_\n",
        "grid.best_score_\n",
        "grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pK3NgUVNdK1A"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "min_samples_splits = np.linspace(0.9, 1.0, 5, endpoint=True)\n",
        "train_results = []\n",
        "test_results = []\n",
        "for min_samples_split in min_samples_splits:\n",
        "   model = GradientBoostingClassifier(min_samples_split=min_samples_split)\n",
        "   model.fit(X_train, y_train)\n",
        "   train_pred = model.predict(X_train)\n",
        "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
        "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "   train_results.append(roc_auc)\n",
        "   y_pred = model.predict(X_test)\n",
        "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "   test_results.append(roc_auc)\n",
        "from matplotlib.legend_handler import HandlerLine2D\n",
        "line1, = plt.plot(min_samples_splits, train_results, 'b', label=\"Train AUC\")\n",
        "line2, = plt.plot(min_samples_splits, test_results, 'r', label=\"Test AUC\")\n",
        "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
        "plt.ylabel(\"AUC score\")\n",
        "plt.xlabel(\"min samples split\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "swLeLKB2tBEW",
        "outputId": "f18ff8e2-4bb1-44b6-b121-c2afe4e860d2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"True\", \"False\"])\n",
        "\n",
        "disp.plot(cmap='Oranges');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "9GXElbnvbsyo",
        "outputId": "7e8f80bf-5df1-409e-8251-df245847b9c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f00cfe500d0>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm = confusion_matrix(y_test, predictions)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"True\", \"False\"])\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "cmp.plot(cmap = 'Oranges', ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15z75iuqaPnR"
      },
      "outputs": [],
      "source": [
        "#QBR_plot = df2['Home QBR'].plot()\n",
        "#QBR_plot.set_xlabel('Sample #')\n",
        "#QBR_plot.set_ylabel('QB Rating')\n",
        "#QBR_plot.set_title('QB Rating For Every Game')\n",
        "#plt.show()\n",
        "\n",
        "#sns.scatterplot(x='Home QBR', y=\"Away QBR\", data=df2);\n",
        "\n",
        "#sns.distplot(x = df2['Home QBR'], bins = 10)\n",
        "\n",
        "#sns.stripplot(y = df2['Dif PPG'], x = df2['Home Favored'])\n",
        "df_1 = df[df['Season'] == 2019]\n",
        "#sns.scatterplot(x = df_1['Dif PPG'], y = df_1['Dif PTS Allowed'], hue = df_1['Home Win'])\n",
        "df_1.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YazSCeBAJ75K"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "#filter\n",
        "#df = df[df['roles'] == 'Student']\n",
        "#df = df[df['mode'] == 'verified']\n",
        "#df[\"passed_class\"] = np.where(df['grade'] >= 0.55, 1, 0)\n",
        "\n",
        "#grab columns that you want\n",
        "df_1 = df[[\"Home QBR\", \"Home PPG\", \"Home TO\", \"Home Win PCT\", \"Home Total Yards\", \"Home Yards Allowed\", \"Home TOP\", \"Home Penalties\", \"Home Win\"]]\n",
        "\n",
        "#get orrelation matrix\n",
        "corrMatrix = df_1.corr()\n",
        "\n",
        "#plot correlation matrix\n",
        "sns.heatmap(corrMatrix, annot=True)\n",
        "sns.set(font_scale=0.8)\n",
        "plt.title(\"Passing Correlation - Verified\", fontsize=15)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "#easy way to grab wanted columns\n",
        "#labels = [\"Home QBR\", \"Home PPG\", \"Home TO\", \"Home Win PCT\"]\n",
        "\n",
        "#plot scatter matrix\n",
        "#fig = px.scatter_matrix(df, dimensions=labels, color=\"Home Win\")\n",
        "#fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxN9eXU3rUmM",
        "outputId": "e45f5069-a2ef-41e6-fc03-373b91aa3033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6254681647940075 (+/- 0.01) [Decision Tree]\n",
            "Accuracy: 0.6142322097378277 (+/- 0.01) [Ada Boost]\n",
            "Accuracy: 0.599250936329588 (+/- 0.01) [Gradient Boosting]\n",
            "Accuracy: 0.5767790262172284 (+/- 0.01) [Logistic Regression]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6292134831460674 (+/- 0.01) [Random Forest]\n",
            "Accuracy: 0.5730337078651685 (+/- 0.01) [SVC]\n",
            "Accuracy: 0.5730337078651685 (+/- 0.01) [KNN]\n",
            "Accuracy: 0.6479400749063671 (+/- 0.01) [GaussianNB]\n",
            "Accuracy: 0.6441947565543071 (+/- 0.01) [BernoulliNB]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6179775280898876 (+/- 0.01) [MLP]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6329588014981273 (+/- 0.01) [Ensemble]\n"
          ]
        }
      ],
      "source": [
        "# Voting Classifier 2018\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier #n_estimators = 80\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier #66.55%: n_estimators = 12, learning_rate = 0.05, max_depth = 1, random_state = 0\n",
        "from sklearn.ensemble import AdaBoostClassifier #66.55%: n_estimators = 3\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from itertools import product\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Training classifiers\n",
        "clf1 = DecisionTreeClassifier(max_depth = 4, min_samples_split = 12, random_state = 0)\n",
        "\n",
        "clf2 = AdaBoostClassifier(n_estimators = 5, learning_rate = 1.85, random_state = 0)\n",
        "\n",
        "clf3 = GradientBoostingClassifier(n_estimators = 116, learning_rate = .65, max_depth = 1, min_samples_split = 14, random_state = 0)\n",
        "\n",
        "clf4 = LogisticRegression(C = 0.09, random_state = 0)\n",
        "\n",
        "clf5 = RandomForestClassifier(n_estimators = 243, max_depth = 17, random_state=0, min_samples_split = 2)\n",
        "\n",
        "clf6 = SVC(C = 20, kernel = \"rbf\", probability = True, random_state = 0)\n",
        "\n",
        "clf7 = KNeighborsClassifier(n_neighbors = 143)\n",
        "\n",
        "clf8 = GaussianNB()\n",
        "\n",
        "clf9 = BernoulliNB(alpha = 12, fit_prior = False)\n",
        "\n",
        "clf10 = MLPClassifier(alpha = 112, max_iter = 70, random_state = 0)\n",
        "\n",
        "eclf = VotingClassifier(estimators=[('dt', clf1), ('ab', clf2), ('gb', clf3), ('lr', clf4), ('rf', clf5), ('svc', clf6), ('knn', clf7), ('gnb', clf8), ('bnb', clf9), ('MLP',clf10)], voting='hard')\n",
        "\n",
        "#params = {'svc__C': [.1, 1, 10, 100], 'svc__kernel': ['linear', 'rbf'], 'rf__n_estimators': [20, 40, 60, 80, 100, 120, 140, 160, 180, 200], 'knn__n_neighbors': [1, 5, 10, 20, 30, 40, 50], 'dt__max_depth': [1, 5, 10, 20, 30, 40,  50], 'dt__min_samples_split': [1, 5, 10, 20, 30, 40, 50], 'ab__n_estimators': [1, 5, 10, 20, 30, 40, 50], 'ab__learning_rate': [0.01, .1, .2, .4, .6, .8, 1], 'gb__n_estimators':[1, 5, 10, 20, 30, 40, 50], 'gb__learning_rate': [0.01, .1, .2, .4, .6, .8, 1], 'gb__max_depth': [1, 5, 10, 20, 30, 40,  50], 'gb__min_samples_split': [1, 5, 10, 20, 30, 40, 50]}\n",
        "\n",
        "#grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)\n",
        "#gridsearch = grid.fit(X_train, y_train)\n",
        "\n",
        "#print(gridsearch.best_params_)\n",
        "#grid_predictions = gridsearch.predict(X_test)\n",
        "\n",
        "#print(accuracy_score(y_test, grid_predictions))\n",
        "\n",
        "for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6, clf7, clf8, clf9, clf10, eclf], ['Decision Tree', 'Ada Boost', 'Gradient Boosting', 'Logistic Regression', 'Random Forest', 'SVC', 'KNN', 'GaussianNB', 'BernoulliNB', 'MLP', 'Ensemble']):\n",
        "  clf.fit(X_train, y_train)\n",
        "  predictions = clf.predict(X_test)\n",
        "  print(\"Accuracy:\", accuracy_score(y_test, predictions), \"(+/- 0.01) [\" + label + \"]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89VwZo5Tfpwd",
        "outputId": "5316dc5f-60c2-43fa-de74-1a479364b9f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6329588014981273 (+/- 0.01) [Decision Tree]\n",
            "Accuracy: 0.6292134831460674 (+/- 0.01) [Ada Boost]\n",
            "Accuracy: 0.6179775280898876 (+/- 0.01) [Gradient Boosting]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.602996254681648 (+/- 0.01) [Logistic Regression]\n",
            "Accuracy: 0.6367041198501873 (+/- 0.01) [Random Forest]\n",
            "Accuracy: 0.6329588014981273 (+/- 0.01) [SVC]\n",
            "Accuracy: 0.599250936329588 (+/- 0.01) [KNN]\n",
            "Accuracy: 0.651685393258427 (+/- 0.01) [GaussianNB]\n",
            "Accuracy: 0.6292134831460674 (+/- 0.01) [BernoulliNB]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (41) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.602996254681648 (+/- 0.01) [MLP]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6329588014981273 (+/- 0.01) [Ensemble]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (41) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "# Voting Classifier 2017\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier #n_estimators = 80\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier #66.55%: n_estimators = 12, learning_rate = 0.05, max_depth = 1, random_state = 0\n",
        "from sklearn.ensemble import AdaBoostClassifier #66.55%: n_estimators = 3\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from itertools import product\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Training classifiers\n",
        "clf1 = DecisionTreeClassifier(max_depth = 3, min_samples_split = 12, random_state = 0)\n",
        "\n",
        "clf2 = AdaBoostClassifier(n_estimators = 10, learning_rate = 1.85, random_state = 0)\n",
        "\n",
        "clf3 = GradientBoostingClassifier(n_estimators = 3, learning_rate = .65, max_depth = 4, min_samples_split = 40, random_state = 0)\n",
        "\n",
        "clf4 = LogisticRegression(C = .05, random_state = 0)\n",
        "\n",
        "clf5 = RandomForestClassifier(n_estimators = 120, max_depth = 5, random_state=0, min_samples_split = 2)\n",
        "\n",
        "clf6 = SVC(C = 19, kernel = \"poly\", degree = 1, probability = True, random_state = 0)\n",
        "\n",
        "clf7 = KNeighborsClassifier(n_neighbors = 102)\n",
        "\n",
        "clf8 = GaussianNB()\n",
        "\n",
        "clf9 = BernoulliNB(alpha = k, fit_prior = False)\n",
        "\n",
        "clf10 = MLPClassifier(alpha = 4, max_iter = 41, random_state = 0)\n",
        "\n",
        "eclf = VotingClassifier(estimators=[('dt', clf1), ('ab', clf2), ('gb', clf3), ('lr', clf4), ('rf', clf5), ('svc', clf6), ('knn', clf7), ('gnb', clf8), ('bnb', clf9), ('MLP',clf10)], voting='hard')\n",
        "\n",
        "#params = {'svc__C': [.1, 1, 10, 100], 'svc__kernel': ['linear', 'rbf'], 'rf__n_estimators': [20, 40, 60, 80, 100, 120, 140, 160, 180, 200], 'knn__n_neighbors': [1, 5, 10, 20, 30, 40, 50], 'dt__max_depth': [1, 5, 10, 20, 30, 40,  50], 'dt__min_samples_split': [1, 5, 10, 20, 30, 40, 50], 'ab__n_estimators': [1, 5, 10, 20, 30, 40, 50], 'ab__learning_rate': [0.01, .1, .2, .4, .6, .8, 1], 'gb__n_estimators':[1, 5, 10, 20, 30, 40, 50], 'gb__learning_rate': [0.01, .1, .2, .4, .6, .8, 1], 'gb__max_depth': [1, 5, 10, 20, 30, 40,  50], 'gb__min_samples_split': [1, 5, 10, 20, 30, 40, 50]}\n",
        "\n",
        "#grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)\n",
        "#gridsearch = grid.fit(X_train, y_train)\n",
        "\n",
        "#print(gridsearch.best_params_)\n",
        "#grid_predictions = gridsearch.predict(X_test)\n",
        "\n",
        "#print(accuracy_score(y_test, grid_predictions))\n",
        "\n",
        "for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6, clf7, clf8, clf9, clf10, eclf], ['Decision Tree', 'Ada Boost', 'Gradient Boosting', 'Logistic Regression', 'Random Forest', 'SVC', 'KNN', 'GaussianNB', 'BernoulliNB', 'MLP', 'Ensemble']):\n",
        "  clf.fit(X_train, y_train)\n",
        "  predictions = clf.predict(X_test)\n",
        "  print(\"Accuracy:\", accuracy_score(y_test, predictions), \"(+/- 0.01) [\" + label + \"]\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTNaDqTQt3tR0fx9C/8l8B",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}